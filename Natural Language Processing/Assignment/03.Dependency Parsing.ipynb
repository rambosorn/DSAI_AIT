{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rambo SORN_st123418"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Assignment - Dependency Parsing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything should be done ON MY code, no new code.\n",
    "\n",
    "\n",
    "1. Read https://aclanthology.org/D14-1082.pdf and maybe just write one paragraph summary in your README.md in your github\n",
    "\n",
    "2. Do something called ablation study (meaning try to delete something so we know the impact of that deleted thing - very common in NLP)\n",
    "Recall that we have 18 word + 18 pos + 12 dep features\n",
    "Try to delete only the 12 dep features and check UAS\n",
    "Try to delete only the 18 pos features and check UAS\n",
    "3. Do another comparison study testing the embedding\n",
    "Chaky uses some embedding\n",
    "Try to use (1) glove embedding (smallest), (2) nn.Embedding (train from scratch) and compare with Chaky's embedding - on how it affects the UAS\n",
    "4. Do some testing, compare 2-3 sentences with spaCy and see whether our neural network gives the same dependency.\n",
    "\n",
    "Criteria:\n",
    "0: not done\n",
    "1: ok\n",
    "2: with comments/explanation like how Chaky does his tutorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improt Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sornr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm  #gimmick for progressbar when you train\n",
    "import pickle #saving and loading models\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parsing function\n",
    "We gonna start with a class Parsing, representing a parser for each sentence. For each sentence, we need the stack, buffer, and the dependencies\n",
    "### Use code from Prof. class lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basically, it takes the current state of the buffer, stack, dependencies\n",
    "#tell us how SHIFT, LA, RA changes these three objects\n",
    "\n",
    "class Parsing(object):\n",
    "    \n",
    "    #init stack, buffer, dep\n",
    "    def __init__(self, sentence):  \n",
    "        self.sentence = sentence     #['The', 'cat', 'sat]  #conll format which is already in the tokenized form\n",
    "        self.stack    = ['ROOT']\n",
    "        self.buffer   = sentence[:]  #in the beginning, everything is inside the buffer\n",
    "        self.dep      = []           #maintains a list of tuples of dep\n",
    "    \n",
    "    #parse function that tells me how shift, la, ra changes these three objects\n",
    "    def parse_step(self, transition):     #transition could be either S, LA, RA\n",
    "        if transition == 'S':\n",
    "            #get the top guy in the buffer and put in stack\n",
    "            head = self.buffer.pop(0)\n",
    "            self.stack.append(head)\n",
    "        elif transition == 'LA':  #stack = [ROOT, He, has] ==> append to dep (has, he) and then He is gone from the stack [ROOT, has]\n",
    "            dependent = self.stack.pop(-2)  #He\n",
    "            self.dep.append((self.stack[-1], dependent))  #(has, he)\n",
    "        elif transition == 'RA':\n",
    "            #can you guys try to this???\n",
    "            dependent = self.stack.pop()  #stack = [ROOT, has, control] ==> dep (has, control), control will be gone fromt he stack [ROOT, has]\n",
    "            self.dep.append((self.stack[-1], dependent))\n",
    "        else:\n",
    "            print(f\"Bad transition: {transition}\")\n",
    "    \n",
    "    #given some series of transition, it gonna for-loop the parse function\n",
    "    def parse(self, transitions):\n",
    "        for t in transitions:\n",
    "            self.parse_step(t)\n",
    "        return self.dep\n",
    "    \n",
    "    #check whether things are finished - no need to do anymore functions....\n",
    "    def is_completed(self):\n",
    "        return (len(self.buffer) == 0) and (len(self.stack) == 1)  #so buffer is empty and ROOT is the only guy in stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a5e0dd1bb1c7782ce55b8cc0782cb511f0ece1dcdb1ee0c0eca7637fe7f72b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
